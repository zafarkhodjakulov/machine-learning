{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gradient Descent: Predicting Car Prices**\n",
    "\n",
    "#### Objective:\n",
    "Your task is to implement and use **Gradient Descent** to optimize a regression model for predicting car prices based on various features. You'll work with a real-world dataset to understand the workings of gradient descent, evaluate its performance, and compare it with other optimization techniques.\n",
    "\n",
    "\n",
    "#### Dataset:\n",
    "Use the **Car Price Prediction Dataset**: `data/car_price.csv`, which contains information on car features and their respective prices. Each row corresponds to a car, and the columns represent various features such as horsepower, engine size, and car dimensions. The target variable is the **car price (in dollars)**.\n",
    "\n",
    "\n",
    "#### Steps to Complete:\n",
    "\n",
    "1. **Data Loading and Exploration**  \n",
    "   - Load the dataset using `pandas`.\n",
    "   - Display the first few rows and explore the dataset to understand the features and their distributions.\n",
    "   - Check for missing values and handle them appropriately.\n",
    "   - Normalize or scale the features to ensure smooth convergence of gradient descent.\n",
    "\n",
    "2. **Define the Linear Regression Model**  \n",
    "   - Create a linear regression model with parameters (weights and biases) initialized to zero or small random values.\n",
    "   - Define the **cost function** as **Mean Squared Error (MSE)**.\n",
    "\n",
    "3. **Implement Gradient Descent**  \n",
    "   - Write a custom implementation of Gradient Descent to optimize the weights and biases of the regression model:\n",
    "     - Compute gradients of the cost function with respect to each parameter.\n",
    "     - Update parameters iteratively using the gradient descent formula:\n",
    "       $$\n",
    "       \\theta := \\theta - \\alpha \\cdot \\nabla J(\\theta)\n",
    "       $$\n",
    "       where $ \\alpha $ is the learning rate.\n",
    "\n",
    "4. **Experiment with Hyperparameters**  \n",
    "   - Test the algorithm with different learning rates ($ \\alpha $).\n",
    "   - Observe and plot the cost function values over iterations to ensure convergence.\n",
    "\n",
    "5. **Model Evaluation**  \n",
    "   - Split the dataset into **training** and **test sets**.\n",
    "   - Evaluate the model's performance on both datasets using:\n",
    "     - Mean Squared Error (MSE)\n",
    "     - R² score\n",
    "   - Compare predictions with actual values.\n",
    "\n",
    "6. **Visualization**  \n",
    "   - Plot the cost function against iterations to visualize convergence.\n",
    "   - Visualize the relationship between key features (e.g., Horsepower) and predicted car prices.\n",
    "\n",
    "\n",
    "#### Bonus Challenges (Optional):\n",
    "\n",
    "1. **Mini-Batch Gradient Descent**:  \n",
    "   - Modify your implementation to use mini-batches instead of the entire dataset for each gradient step.\n",
    "   - Compare the performance and convergence speed of batch and mini-batch gradient descent.\n",
    "\n",
    "2. **Stochastic Gradient Descent (SGD)**:  \n",
    "   - Implement stochastic gradient descent and compare its performance with batch gradient descent.\n",
    "\n",
    "3. **Multiple Models**:  \n",
    "   - Train and evaluate the same dataset using **Scikit-learn's LinearRegression** for comparison.\n",
    "\n",
    "4. **Polynomial Features**:  \n",
    "   - Add polynomial terms for key features (e.g., horsepower squared) to improve model performance and evaluate the impact of feature engineering.\n",
    "\n",
    "\n",
    "#### Deliverables:\n",
    "- A Python script or Jupyter Notebook containing:\n",
    "  - Code for loading and preprocessing the data.\n",
    "  - Implementation of Gradient Descent for linear regression.\n",
    "  - Results of model training and evaluation.\n",
    "  - Visualizations of cost function convergence and predictions.\n",
    "- A brief report answering:\n",
    "  - How does the learning rate affect convergence?\n",
    "  - What were the final MSE and R² scores?\n",
    "  - Insights from comparing different optimization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
