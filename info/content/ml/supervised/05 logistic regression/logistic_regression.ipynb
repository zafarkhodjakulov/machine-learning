{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression** is a supervised learning algorithm that can be used to classify data into categories, or classes, by predicting the probability that an observation falls into a particular class based on its features.\n",
    "\n",
    "Though it can be extended to more than two categories, logistic regression is often used for binary classification, i.e. determining which of two groups a data point belongs to, or whether an event will occur or not.\n",
    "\n",
    "The typical setup for logistic regression is as follows: there is an outcome $y$ that falls into one of two categories (say 0 or 1), and the following equation is used to estimate the probability that $y$ belongs to a particular category given inputs $X = (x_1,x_2,\\dots,x_k)$\n",
    "\n",
    "$$\n",
    "P(y=1 \\mid X) = \\text{sigmoid}(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "z = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + \\dots + \\hat{\\beta}_k x_k\n",
    "$$\n",
    "\n",
    "The equation for $z$ likely looks familiar. This is called a linear predictor, and it is transformed by the sigmoid function so that the values fall between 0 and 1, and can therefore be interpreted as probabilities. This resulting probability is then compared to a threshold to predict a class for $y$ based on $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y=1 \\mid X) = \\frac{1}{1 + e^{-(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + \\dots + \\hat{\\beta}_k x_k)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How It Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s make this a bit more concrete by walking through an example. Suppose that you want to go for a hike in Seattle. You want to predict whether it will be sunny or rainy, so that you can decide whether to hike or drink coffee indoors at a local cafe. You know that it rains often in Seattle, but you’ve heard the summers have nice weather. The question is: can we predict the weather, given factors such as the temperature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume there are two classes: Rainy Days and Sunny Days. We can assign a numeric value of 0 and 1 to each class, say 0 to a Rainy Day and 1 to a Sunny Day. We have one continuous feature: the temperature, in degrees Fahrenheit. For each day, we can plot this value along with the corresponding temperature.\n",
    "\n",
    "<img src=\"images/weather_predict_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, we should not fit a linear regression model to these data. The outcomes of a linear regression model can take any numerical value, but these data can only take on outcomes of 0 or 1, so the predictions of a linear model may not be meaningful.\n",
    "\n",
    "Instead, we can fit a logistic function to the data. The values of this function can be interpreted as probabilities, as the values range between 0 and 1. We can interpret the line as the probability of a sunny day given a particular temperature.\n",
    "\n",
    "<img src=\"images/weather_predict_2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the logistic function to predict the probabilities of each outcome, we can predict the class. We use a classification threshold, or decision boundary, to decide the predicted class based on the probability of each class given the feature values. A typical threshold is 0.5, where we predict an outcome will occur if the probability of that outcome is greater than 0.5. This threshold can be adjusted — for example, if you really dislike the rain, you may want to set the threshold higher to be more cautious, so that that you predict a sunny day and go hiking only if the probability of a sunny day exceeds that threshold.\n",
    "\n",
    "<img src=\"images/weather_predict_3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting our model, the goal is to find the parameters that optimize a function that defines how well the model is performing. Put simply, the goal is to make predictions as close to 1 when the outcome is 1 and as close to 0 when the outcome is 0. In machine learning, the function to be optimized is called the loss function or cost function. We use the loss function to determine how well our model fits the data.\n",
    "\n",
    "\n",
    "A suitable loss function in logistic regression is called the Log-Loss, or binary cross-entropy. This function is:\n",
    "\n",
    "$$\n",
    "\\text{Log-Loss} = \\sum_{i=0}^{n} - \\left( y_i \\cdot \\log(p_i) + (1 - y_i) \\cdot \\log(1 - p_i) \\right)\n",
    "$$\n",
    "\n",
    "where $n$ is the number of samples, indexed by $i$, $y_i$ is the true class for the index $i$, and $p_i$ is the model prediction for the index $i$. Minimizing the $\\text{Log-Loss}$ is equivalent to maximizing the Log-Likelihood, since the $\\text{Log-Loss}$ is the negative of the Log-Likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we find the coefficients $ (\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_k) $ that minimize the loss function? There are two main approaches for logistic regression: gradient descent and maximum likelihood estimation. We’ll briefly discuss both here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to estimate coefficients is to use gradient descent. In gradient descent, the goal is to minimize the Log-Loss cost function over all samples. This method involves selecting initial parameter values, and then updating them incrementally by moving them in the direction that decreases the loss. At each iteration, the parameter value is updated by the gradient, scaled by the step size (otherwise known as the learning rate). The gradient is the vector encompassing the direction and rate of the fastest increase of a function, which can be calculated using partial derivatives. The parameters are updated in the opposite direction of the gradient by the step size in an attempt to find the parameter values that minimize the Log-Loss.\n",
    "\n",
    "Because the gradient calculates where the function is increasing, going in the opposite direction leads us to the minimum of our function. In this manner, we can repeatedly update our model's coefficients such that we eventually reach the minimum of our error function and obtain a sigmoid curve that fits our data well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is finding the model that maximizes the likelihood of observing the data by using Maximum Likelihood Estimation (MLE). It turns out, minimizing the Log-Loss is equivalent to maximizing the Log-Likelihood. Therefore, the goal is to find the parameter values that maximize the following:\n",
    "\n",
    "$$\n",
    "\\text{Log-Likelihood} = \\sum_{i=0}^{n} \\left( y_i \\cdot \\log(p_i) + (1 - y_i) \\cdot \\log(1 - p_i) \\right)\n",
    "$$\n",
    "\n",
    "We can do so by differentiating the Log-Likelihood with respect to the parameters, setting the derivatives equal to 0, and solving the equation to find the estimates of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building in Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the diabetes prediction model using a logistic regression classifier.\n",
    "\n",
    "Let's first load the required **Pima Indian Diabetes** dataset using the pandas' read CSV function. You can download data from the following link:\n",
    "<a src=\"https://www.kaggle.com/uciml/pima-indians-diabetes-database\">https://www.kaggle.com/uciml/pima-indians-diabetes-database</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "pima = pd.read_csv(\"data/pima-indians-diabetes.csv\")\n",
    "pima.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting features\n",
    "Here, you need to divide the given columns into two types of variables dependent(or target variable) and independent variable(or feature variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima.drop(columns=['label'])\n",
    "y = pima.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the Dataset is broken into two parts in a ratio of 75:25. It means 75% data will be used for model training and 25% for model testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model development and prediction\n",
    "First, import the LogisticRegression module and create a logistic regression classifier object using the `LogisticRegression()` function with random_state for reproducibility.\n",
    "\n",
    "Then, fit your model on the train set using `fit()` and perform prediction on the test set using `predict()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=16)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table that is used to evaluate the performance of a classification model. You can also visualize the performance of an algorithm. The fundamental part of a confusion matrix is the number of correct and incorrect predictions summed up class-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,   9],\n",
       "       [ 25,  42]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see the confusion matrix in the form of the array object. The dimension of this matrix is 2*2 because this model is binary classification. You have two classes 0 and 1. Diagonal values represent accurate predictions, while non-diagonal elements are inaccurate predictions. In the output, 116 and 42 are actual predictions, and 25 and 9 are incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing confusion matrix using a heatmap\n",
    "\n",
    "Let's visualize the results of the model in the form of a confusion matrix using matplotlib and seaborn.\n",
    "\n",
    "Here, you will visualize the confusion matrix using Heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = [0, 1] # name of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap='YlGnBu', fmt='g')\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix evaluation metrics\n",
    "Let's evaluate the model using classification_report for accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "without diabetes       0.82      0.93      0.87       125\n",
      "   with diabetes       0.82      0.63      0.71        67\n",
      "\n",
      "        accuracy                           0.82       192\n",
      "       macro avg       0.82      0.78      0.79       192\n",
      "    weighted avg       0.82      0.82      0.82       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['without diabetes', 'with diabetes']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# TODO: Write description about metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources for this content:\n",
    "\n",
    "<a href=\"https://mlu-explain.github.io/logistic-regression/\">Logistic Regression for Classification</a>\n",
    "\n",
    "<a href=\"https://www.datacamp.com/tutorial/understanding-logistic-regression-python\">\n",
    "Understanding Logistic Regression in Python</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
